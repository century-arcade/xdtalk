<!DOCTYPE html>
<html>
  <head>
    <title>How a File Format Led to a Crossword Scandal</title>

    <meta charset="utf-8">
    <style>
        @font-face{
          font-family: 'Droid Serif';
          font-style: normal;
          font-weight: 400;
          src: local('Droid Serif Regular'), local('DroidSerif-Regular'), url(fonts/droidserif.woff2) format('woff2');
          unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
        }
        @font-face{
            font-family: 'Yanone Kaffeesatz';
            src: local('Yanone Kaffeesatz Regular'), local('YanoneKaffeesatz-Regular'), url('fonts/yanonekaffeesatz.woff2') format('woff2');
            font-style: normal;
            font-weight: 400;
            unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
        }
        @font-face {
          font-family: 'Ubuntu Mono';
          font-style: normal;
          font-weight: 400;
          src: local('Ubuntu Mono'), local('UbuntuMono-Regular'), url(fonts/ubuntumono.woff2) format('woff2');
          unicode-range: U+0000-00FF, U+0131, U+0152-0153, U+02BB-02BC, U+02C6, U+02DA, U+02DC, U+2000-206F, U+2074, U+20AC, U+2122, U+2191, U+2193, U+2212, U+2215, U+FEFF, U+FFFD;
        }

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: 400;
        margin-bottom: 0;
      }
      .remark-code .remark-inline-code {font-family: 'Ubuntu Mono'; }
      .remark-slide-content blockquote { font-size: 2.0em; }
      .remark-slide-content h1 { font-size: 4.5em; }
      .remark-slide-content h2 { font-size: 3em; }
      .remark-slide-content h3 { font-size: 2em; }

      .remark-slide-content li { font-size: 2.5em; text-align: left}
      .remark-slide-content li li { font-size: 1em;}
      .footnote {
          position: absolute;
          bottom: 3em;
          right: 7em;
      }
      .em2 .remark-code-line { font-size: 1.2em; }
      .image-70 img { width: 70%; }
      .image-80 img { width: 80%; }
      .image-90 img { width: 90%; }
      .image-100 img { width: 100%; }
      .image-110 img { width: 110%; }

      /* Two-column layout */
            .left-column {
        width: 20%;
        height: 92%;
        float: left;
      }
        .left-column h2:last-of-type, .left-column h3:last-child {
          color: #000;
        }
      .right-column {
        width: 75%;
        float: right;
        padding-top: 1em;
      }

      .remark-code-line {
          font-size: 2em;
      }

      .image-tw img {
          width: 100px;
      }

      span.callout {
           background: yellow;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
<link rel="StyleSheet" type="text/css" href="saulpw-style.css"/>
  </head>
  <body>
    <textarea id="source">
class: center, middle
.image-70[![how-could-you-know](images/cross-8-2.png)]
???
- Thank you for having me
- grateful for being able to share this story with you
---
class: middle

## A little while ago on a computer not too far away....

???

- The year was 2016
- a software engineer was playing with some crossword data
- and discovered hundreds of crosswords that were near-duplicates
- of previously published crosswords.
- He showed the evidence to the crossword construction list he was on

---
class: center

.image-tw[![](images/twitter-logo.png)]

<blockquote class="titter-tweet tw-align-center" data-lang="en"><p lang="en" dir="ltr">Had a xword in USA Today 2004. They tweaked it in 2008 w/pseudonym. Then ran it AGAIN in 2015. Seedy business indeed </p>&mdash; Ben Tausig (@datageneral) <a href="https://twitter.com/datageneral/status/702973432745615360?ref_src=twsrc%5Etfw">February 25, 2016</a></blockquote>


???
- a tweet was posted
- "Had a crossword in USA Today in 2004, They tweaked it in 2008 w/pseudonym.  Then ran it AGAIN in 2015.  Seedy business indeed."
- that was from the editor of the American Values Club crossword

---
class: center

.image-70[![crossword-scandal](images/crossword-scandal.png)]
???
- soon after, an article was published in 538
- spinning it into a plagiarism scandal
---
class: center, middle

.image-tw[![](images/twitter-logo.png)]

<blockquote class="titter-tweet tw-align-center" data-lang="en"><p lang="en" dir="ltr">i&#39;m told the Tim Parker/<a href="https://twitter.com/hashtag/gridgate?src=hash&amp;ref_src=twsrc%5Etfw">#gridgate</a> crossword scandal will have a segment on <span class="callout">CBS Evening News</span> tonight. <br></p>&mdash; Oliver Roeder (@ollie) <a href="https://twitter.com/ollie/status/706562132154908673?ref_src=twsrc%5Etfw">March 6, 2016</a></blockquote>
???
- It blew up into hashtag gridgate
- and was in the mainstream news for a cycle.

---
exclude: true
class: center, middle
<blockquote class="twitter-tweet tw-align-center" data-lang="en"><p lang="en" dir="ltr">UPDATE: Tim Parker&#39;s Wiki page is now protected from his own shameful edit warring. <a href="https://twitter.com/hashtag/gridgate?src=hash&amp;ref_src=twsrc%5Etfw">#gridgate</a></p>&mdash; Maximillian Sherer (@Xmaster8621) <a href="https://twitter.com/Xmaster8621/status/706533219076874240?ref_src=twsrc%5Etfw">March 6, 2016</a></blockquote>
???
The accused got into an edit war on Wikipedia.
---
exclude: true
class: center

.image-70[![crossword-scandal](images/usa-boycott.png)]
---
.image-90[![crossword-scandal](images/usa-fired.png)]
.image-90[![crossword-scandal](images/timothy-parker.png)]

???
- a major crossword editor
- had been engaging in plagiarism
- on a grand scale
- for several years
---
class:center, middle

# Everyone loves a scandal

<br/>
<br/>

## How did this happen to be discovered?


???

- these crosswords had been publicly available
- including historical ones
- since the crosswords were 're'published
- why did this go undiscovered for so long?

---
class:middle

<blockquote>“when you get the data into a <b>nice</b>, <b>clean</b>, <b>dense</b> form, stuff just falls out of it”
</blockquote>
### &mdash; me
???
- the 538 article hints at it w/ something I said
- "when you get data into a nice, clean, dense form, stuff just falls out of it"
-  I said this off-the-cuff, but it's an accurate statement of the thesis I was testing at the time
- the format and organization were instrumental, maybe essential, to the discovery and end result.
---
class: middle, center
### How a
## File Format
### led to a
## Crossword Scandal

### Saul Pwanson

.footnote[xd.saul.pw]
???
- so this is how a file format
- led to a crossword scandal

---
class: middle, center

.image-100[![motivation](images/motivation.jpg)]

???
- My original motivation for looking into crossword data was benign
- I had tried my hand at crossword construction
- frustrating and tedious
- wanted to get better
- software engineer
- what else would you expect
- thought I would just get some data
- and do some "analysis"

---

class: center
# xwordinfo.com

.image-100[![xwordinfo](images/xwordinfo.png)]

???

- there is a site, xwordinfo
- which makes ALL of the NYTimes puzzles available
- over 24,000 puzzles dating back to 1942

- This is thanks to 3 years of work by the Pre-Shortzian Puzzle Project
- led by David Steinberg, who was a teenager at the time,
- a group of several hundred crossword enthusiasts, spent 3 years
- digging into microfiche and transcribing every NYT puzzle that had ever been published

- This is a great source of data
- I emailed and asked to download their data in bulk
- I got a very nice reply from Jeff Chen, who runs the site and is very active in the crossword community
- and the reply was very polite, but it said, in essence,
---

class: center
# xwordinfo.com

# "no"
???

- "no".

- So as trivial as crosswords are,
- the collection of historical crossword data is exceedingly non-trivial,
- and even in this case, having the lion's share of the work already done
- concerns about copyright were going to make it unnecessarily difficult for me.
---
class: center
# xwordinfo.com

- I can "just" scrape it

???
- I am not one to be so easily discouraged.
- After all, I can just scrape it
- but scraping is a pain, and I was sick of doing one-off data collections
- it would really be too much work to do it just for my little experiment in crossword construction.
- so I decided to double down
- and do it -- once and for all

---
class: center
# Once and For All

- archival format for analysis

- gift to future scholars
???
- I decided that I wanted to archive this data for posterity
- xwordinfo only has NYTimes crosswords.
- there are many other publications that have their own crosswords
- but that data is scattered across many sites
- and, the data is in many different formats, some of which are quite difficult to parse
- so this would be a gift to future crossword scholars

---

class: center

# Plan

1. High Potential Format

2. ???

3. Profit
???
- I had a thesis which I mentioned in the opening
- get the data into a "High Potential Format"
- and then I don't know what
- and then profit!
---
class: center
# High Potential Format

???
- or HPF as I like to call it

---
class: center
# High Potential Format

</br>
- neat

???
- neat
  - tidy, organized
  - a place for everything and everything in its place
  - remember, it's not hoarding if it's organized

---
class: center
# High Potential Format

- neat

- clean

???
- clean
  - properly decoded
  - trustworthy as a source
  - structurally correct
  - ready to be grouped and sorted

---
class: center
# High Potential Format

- neat

- clean

- dense
???
- dense
  - exhibits high data locality
  - on any axis that data can be sliced, it's reasonably easy to slice it that way

---
class: center
# Existing Standards

- **puz**: binary, proprietary

- **txt**: text with &lt; TAGS &gt;

- **xpf**: XML

- **ipuz**: JSON

???
- like a good engineer
- i looked at existing formats
- the granddaddy of crossword formats
   - acrosslite .puz
   - ubiquitous, de facto standard
   - binary, and proprietary
- acrosslite also has a very old .txt format
   - has HTML-like tags
   - fragile: clues aren't numbered, don't include answers
      - any extra line in the clues will render the puzzle undecipherable
- xpf is a little more modern, but is based on XML (yuck)
- ipuz is fairly new, and based on JSON
   - meh
- so like a bad engineer

---
## **nyt1955-01-01**.xd

.em2[
```
Title: New York Times, Saturday, January 1, 1955
Author: Anthony Morse
Editor: Margaret Farrar
Rebus: 1=HEART 2=DIAMOND 3=SPADE 4=CLUB
Date: 1955-01-01
```

.left-column[
```
1ACHE#ADAM#2LIL
BLUER#GULL#MATA
EATIN#APEX#ICER
ATAR#TILE#SNEAK
TEN#MANI#ITE###
##DRUB#CANASTAS
FADED#BAGGY#OIL
ONES#KATES#TUNA
ETA#JOKER#JORUM
SILLABUB#SOON##
###ACE#RUIN#ARK
3WORK#JINX#4MAN
BIRD#WADS#SCENE
ISLE#EDGE#PANEL
DEER#BEET#ARTEL
```
]
.right-column[
```
    A1. Sadness. ~ HEARTACHE
    A6. Progenitor. ~ ADAM
    A10. Mae West stand-by. ~ DIAMONDLIL
    A14. Ultramarine plus. ~ BLUER
    A15. Sea bird. ~ GULL
    A16. ___ Hari. ~ MATA
    A17. Stay home for dinner. ~ EATIN
    A18. Peak. ~ APEX
    A19. Deep freeze. ~ ICER
    A20. Ralph Rackstraw, for instance. ~ ATAR
    A21. Scrabble adjunct. ~ TILE
    A22. A lead from a singleton. ~ SNEAK
    A23. Lowest honor. ~ TEN
    A24. Peanut: Spanish. ~ MANI
    A25. Native of: Suffix. ~ ITE
    A26. Administer a sound defeat. ~ DRUB
    [...]
```
]
]
???
- i decided to make my own format
- specifically for archival and analysis

- this is the .xd format I designed

- it's really just a carefully constructed text file
- but it's very easy to parse
   - the structure and format is self-evident

- id is mnemonic and easy to type--a short and recognizable abbreviation for each publication, along with the date
  - here nyt means 'nytimes', and the date is in Y-M-D format, which makes it easily sortable in time
- so overall this id has some good shelving properties

- inside the file, crosswords basically have 3 sections
---
## nyt1955-01-01.xd

.em2[
<b>
```
Title: New York Times, Saturday, January 1, 1955
Author: Anthony Morse
Editor: Margaret Farrar
Rebus: 1=HEART 2=DIAMOND 3=SPADE 4=CLUB
Date: 1955-01-01
```
</b>

.left-column[
```
1ACHE#ADAM#2LIL
BLUER#GULL#MATA
EATIN#APEX#ICER
ATAR#TILE#SNEAK
TEN#MANI#ITE###
##DRUB#CANASTAS
FADED#BAGGY#OIL
ONES#KATES#TUNA
ETA#JOKER#JORUM
SILLABUB#SOON##
###ACE#RUIN#ARK
3WORK#JINX#4MAN
BIRD#WADS#SCENE
ISLE#EDGE#PANEL
DEER#BEET#ARTEL
```
]
.right-column[
```
    A1. Sadness. ~ HEARTACHE
    A6. Progenitor. ~ ADAM
    A10. Mae West stand-by. ~ DIAMONDLIL
    A14. Ultramarine plus. ~ BLUER
    A15. Sea bird. ~ GULL
    A16. ___ Hari. ~ MATA
    A17. Stay home for dinner. ~ EATIN
    A18. Peak. ~ APEX
    A19. Deep freeze. ~ ICER
    A20. Ralph Rackstraw, for instance. ~ ATAR
    A21. Scrabble adjunct. ~ TILE
    A22. A lead from a singleton. ~ SNEAK
    A23. Lowest honor. ~ TEN
    A24. Peanut: Spanish. ~ MANI
    A25. Native of: Suffix. ~ ITE
    A26. Administer a sound defeat. ~ DRUB
    [...]
```
]
]
???
- 1) metadata, at the top
   - key colon value pairs
   - standard crossword keys: title, author, editor, date, copyright
   - extensible by using other metadata keys, like "Rebus" for puzzles which have grid squares with a symbol or more than one letter in them
---
.em2[
## nyt1955-01-01.xd
```
Title: New York Times, Saturday, January 1, 1955
Author: Anthony Morse
Editor: Margaret Farrar
Rebus: 1=HEART 2=DIAMOND 3=SPADE 4=CLUB
Date: 1955-01-01
```

<b>
.left-column[
```
1ACHE#ADAM#2LIL
BLUER#GULL#MATA
EATIN#APEX#ICER
ATAR#TILE#SNEAK
TEN#MANI#ITE###
##DRUB#CANASTAS
FADED#BAGGY#OIL
ONES#KATES#TUNA
ETA#JOKER#JORUM
SILLABUB#SOON##
###ACE#RUIN#ARK
3WORK#JINX#4MAN
BIRD#WADS#SCENE
ISLE#EDGE#PANEL
DEER#BEET#ARTEL
```
]
</b>

.right-column[
```
    A1. Sadness. ~ HEARTACHE
    A6. Progenitor. ~ ADAM
    A10. Mae West stand-by. ~ DIAMONDLIL
    A14. Ultramarine plus. ~ BLUER
    A15. Sea bird. ~ GULL
    A16. ___ Hari. ~ MATA
    A17. Stay home for dinner. ~ EATIN
    A18. Peak. ~ APEX
    A19. Deep freeze. ~ ICER
    A20. Ralph Rackstraw, for instance. ~ ATAR
    A21. Scrabble adjunct. ~ TILE
    A22. A lead from a singleton. ~ SNEAK
    A23. Lowest honor. ~ TEN
    A24. Peanut: Spanish. ~ MANI
    A25. Native of: Suffix. ~ ITE
    A26. Administer a sound defeat. ~ DRUB
    [...]
```
]
]
???
- 2) then there's the **grid**
   - the actual solution to the puzzle
   - one character per grid square
   - and an octothorpe to indicate black squares
---

.em2[
## nyt1955-01-01.xd

```
Title: New York Times, Saturday, January 1, 1955
Author: Anthony Morse
Editor: Margaret Farrar
Rebus: 1=HEART 2=DIAMOND 3=SPADE 4=CLUB
Date: 1955-01-01
```

.left-column[
```
1ACHE#ADAM#2LIL
BLUER#GULL#MATA
EATIN#APEX#ICER
ATAR#TILE#SNEAK
TEN#MANI#ITE###
##DRUB#CANASTAS
FADED#BAGGY#OIL
ONES#KATES#TUNA
ETA#JOKER#JORUM
SILLABUB#SOON##
###ACE#RUIN#ARK
3WORK#JINX#4MAN
BIRD#WADS#SCENE
ISLE#EDGE#PANEL
DEER#BEET#ARTEL
```
]

<b>
.right-column[
```
    A1. Sadness. ~ HEARTACHE
    A6. Progenitor. ~ ADAM
    A10. Mae West stand-by. ~ DIAMONDLIL
    A14. Ultramarine plus. ~ BLUER
    A15. Sea bird. ~ GULL
    A16. ___ Hari. ~ MATA
    A17. Stay home for dinner. ~ EATIN
    A18. Peak. ~ APEX
    A19. Deep freeze. ~ ICER
    A20. Ralph Rackstraw, for instance. ~ ATAR
    A21. Scrabble adjunct. ~ TILE
    A22. A lead from a singleton. ~ SNEAK
    A23. Lowest honor. ~ TEN
    A24. Peanut: Spanish. ~ MANI
    A25. Native of: Suffix. ~ ITE
    A26. Administer a sound defeat. ~ DRUB
    [...]
```
</b>
]
]
???
- 3) finally, there are the clues
   - here, unlike in other formats
   - clues are self-contained, one per line
   - including the dir/number
   - and the ANSWER, after a ~ tilde


- this format is 'stable'
   - if multiple people 'litzed' the same crossword from the same source,
   - they should get identical .xd files, and shelved under an identical id

- this format is also robust to hand-editing
   - if a structural mistake is discovered, the original puzzle should be able to be reconstructed


---
class: center
# Scraping Montage

* 24,400 NY Times
* 3,650 USA Today
* 3,650 Universal uClick
* 300 Chronicle of Higher Ed.
* 180 LA Times

## (2 months)
???
- so then I put the format into action
- if they made a movie about this, this is where the montage would go
   - (i don't know what song they would use though)
- made a janky pipeline to scrape, convert, and shelve crosswords
- I got the 24,000 puzzles from xwordinfo
- i found other public crossword sites and scraped them
- most crossword sites only go back 6 months or a year; 
- and there are many syndicated sites to wade through
    - the same puzzles published on a staggered schedule
- but, I found a site that had the past 10 years of USA Today puzzles
- and then found a site that had crosswords going back 10 years from universal uClick (a major crossword syndication)
- this took about 2 months of regular work in the evenings and on weekends
---
exclude: true
class: center
# Shoutout to ETL

- Extract then Transform
- always save raw source data
- reproducible pipeline
???
- separate Extract from Transform
- save the scraped data in its raw format
- always start transform from raw source data
- because transform will require many iterations
- and have a reproducible pipeline
---
class: center
# gxd

- 30,000 crosswords

- organized on filesystem

- .xd text format

- :D
???
- so now I had the start of God's own crossword corpus
- 30,000 crosswords
- organized on the filesystem
- in a simple text format of my own design
- this is all I wanted in the first place
- so I should be happy, right?
---
class: middle,center
# But am I ever happy?

???
- but instead, I was tired
- things had started getting busy at work
- bored with the project
- I kind of wanted someone else to take up the analysis
---
## Reddit (r/datasets)
<blockquote>
    "I'd like to share it with <b>people who can do better analysis than I can</b>."
</blockquote>

<blockquote>
"Here they are, <b>organized and cleaned and reduced to their utter essence, in a carefully designed bulk text format</b>."
</blockquote>
???
- so i posted a link to the data to reddit in r/datasets
- "to share it with people who can do better analysis than I can"
- they are "organized and cleaned and reduced to their utter essence, in a carefully designed bulk text format"
- i was proud of the work I had done
- i just didn't have the energy to do anything more with it
---
class: middle, center
# Sometimes I play chicken with myself
???
- or so I thought
- because when I sent it out into the world
- that apparently inspired me enough to play with the data just a little
- clean dataset makes for easy exploration
- like nerd-sniping; i kind of nerd-sniped myself
- and decided I could look for an hour or two
---
class: center
# First question

- any patterns in grid fill?

???

- the first question I had
- are they any patterns in grid fill?
- maybe identical corners or sections?
- then I thought, hey
-  it would be really easy with this format to find if there are any duplicate full rows

---
# Identical rows?

```shell
    grep -rh '#' gxd/
    | sort
    | uniq -c
    | sort -nr
```
???
- so i used my trusty unix utilities, grep, sort, uniq
- which come standard on any linux or os/x system
- and work great with simple text
- and I wrote a "query" against my "database"
---
# Identical rows?

     13 #FLASHINTHEPAN#
     12 MERRYGOROUND###
     12 #CREAMOFTHECROP
     12 AROUNDTHECLOCK#
     12 #ANIMALCRACKERS
     12 #ABRAHAMLINCOLN
     11 #WHITEELEPHANT#
     11 TOOTHANDNAIL###
     11 ROMEOANDJULIET#
     11 ###PERFECTPITCH
     11 #KARENCARPENTER
     11 ###HASTYPUDDING
     [...]

???
- which took less than 5 seconds to run
- and this is literal output from that command

- these are theme answers
- themes are like the backbone of most crossword puzzles
- the punny grammatical overreaches that make people groan
- they're an interesting slice of culture
- you can see some familiar idioms here, FLASH IN THE PAN, TOOTH AND NAIL
- so i looked into some of these duplications..
- it looked like themes are reused more often than you might think

---
# Identical non-theme rows?

```shell
    grep -rh '.+#.+#.+' gxd/
    | sort
    | uniq -c
    | sort -nr
```
???
- okay, how about identical non-theme rows?
- changed the query slightly
- this took another few seconds to complete
---
# Identical non-theme rows?

      5 ##UTILE#FOUR###
      5 TRAIN##ADA#ATIP
      5 SLAP#MATTE#NORA
      5 SLAM#AMONG#ODIE
      5 SIRES##ALES#GEO
      5 SINGE#LONE#AMEN
      5 PYRE#CLOSES#DNA
      5 PTAS#ABIES#PEAS
      5 ONUSES#LSTS#ERE
      5 ODES#CLIENT#NAT
      5 OATH#AMOCO#ISEE
      5 NAY#RECYCLE#SAM
      [...]
???

- turned out that many lines had duplicates in other puzzles
- so i used another standard tool, diff, to compare the .xd files
- and that showed that were not actually reprints; only some of the puzzle was changed
- even more, the attributions for the puzzles were different
- so i pulled on that thread, which kept me going
- led to another, and another
- (that weekend is kind of a blur)
- by the end I had found many interesting 'anomalies'
---
.image-110[![nyt](images/nyt-diff.png)]

???
- for instance, this was the largest timespan difference
- originally published in the NYTimes in 1955 and credited to Jack Luzzato
- a nearly identical grid was published in the NYT in 1984, 29 years later, credited to Daniel Girardi
- in this diff, colors indicate changes
- only two letters in the grid have changed
- but nearly every clue in the entire puzzle was rewritten
---
class: middle, center

## 2 lines of Python

```python
hd = difflib.HtmlDiff()
hd.make_table(xd1, xd2)
```
???
- This diff output, btw, was made with just two lines of python code using difflib
- this was enabled by having the data in a the presentable text format in the first place
- it's not the prettiest, but it is completely functional
- and it's accessible to everyone, including non-technical people
---
.image-110[![timburr](images/liz-gorski-without.png)]
???
- here is another "anomaly" that I was very curious about
- it turned that many of the duplicated puzzles had something in common
---
.image-110[![timburr](images/liz-gorski.png)]
???
- edited by a "Timothy Parker"
   - who was the editor of both Universal uClick and USA Today crosswords
- at the time, I knew nothing about the crossword industry
- so I thought might be a fake name, a pseudonym for a syndicate of constructors
- until I found his Wikipedia entry and his claim of a Guinness record for "most syndicated constructor"
- I spent more than a few brain cycles trying to come up with reasons why his puzzles might be legitimately re-attributed

- this puzzle was the real clincher though
   - The puzzle on the right is from USA Today, 2013
   - by "Elizabeth Gorski", a prolific constructor
   - well-known and well-loved in the crossword community.
   - On the left, published by Universal uClick in 2006 (7 years earlier)
   - attributed to someone named "Tim Burr"
   - what was going on?
   - why would a major newspaper republish an old crossword attributed to an obvious pseudonym,
   -  and then change the attribution to someone who really existed?

---
### xd.saul.pw/diffs
----

.image-100[![timburr](images/xd-diffs.png)]
???
- I wrote a grid comparator and ran it over all the puzzles
- I threw this list together to enumerate the "anomalies"
- comprehensive, but minimum effort
- sorted simply by grid similarity
- and I put it up on my website
- linking to those scrappy diffs that we just saw
---
### email to cruciverb-l
### (3 days after r/datasets)

<blockquote>
"I found some <b>pairs of crosswords that are strikingly similar</b>...
</blockquote>
<blockquote>
    I wonder if <b>"Timothy Parker" might be a little loose with attribution</b>...
</blockquote>
<blockquote>
<b>I present this as a curiosity</b>... Please also pardon the 'interface'.
</blockquote>
???
- so three whole days after I posted to reddit/datsaets, I sent this to the crossword list
- I pulled out 3 examples, the 2 we saw and one other
- and said "I found some pairs of crosswords that are strikingly similar"
- I wondered if "Timothy Parker might be a little loose with attribution"
- and "I present this as a curiosity"
- was careful not to use the P-word
- crosswords may be trivial, but the crossword community takes them very seriously
---
class: middle, center
# People took a interest

???
- well, suffice to say, "people took a interest"
- The first response was "You may be onto something here"
- there was much discussion on the list and off
- this is where Ben Tausig got his information, and posted to twitter as we saw in the intro

- As the hubbub grew louder
- I took advantage of peoples' interest in my work.
- Someone on the crossword list publishes a huge clue/answer database once a quarter
- so I asked him for the collection of puzzles I knew he must have
- he would not have given it to me before #gridgate blew up
- but since it had, he "asked his source for permission", and then did give it to me
- again, it's a shame that this data does exist but is so difficult to obtain
- anyway, I got the dataset

---
class: center
# The motherlode

- 80,000 crosswords in .puz

- Thanks to Barry Haldiman

???
- holy forking shirtballs
- I thought 30,000 crosswords was a lot
- This collection had almost 80,000 puzzles in it

- a shoutout to Barry Haldiman,
- who collected crosswords diligently for over 20 years
- and saved everything in the source .puz format!

---
class: middle, center

# (5 days after r/datasets)
???
- I spent the next week, before the 538 article was published
- ingesting 1000s more crosswords with my janky pipeline
- discovering what directories and filenames meant in the motherlode
- shelving crosswords properly in the xd corpus
- figuring out the overlap between this collection and mine
    - which was substantial but not total.

- I compared grids exhaustively, night and day
   - I would start a batch before going to sleep, and another before going to work
- I discovered that week that managing 50,000 of anything is pretty challenging
- esp under time pressure

---
class: center
## Take 2: xd.saul.pw/xdiffs

.image-70[![xdiffs](images/xdiffs.png)]

### (10 days since r/datasets)

???

- this is the second iteration of results that I pushed online
- now there were 50k crosswords
- in this version
- you can click through to each publisher
- and this is what was linked from 538 article
- (all these old urls are still available, btw, because I take my responsbility as a data nerd seriously)
- now at this point, it had been 10 days since I posted to reddit/datasets trying not to do the analysis work.
- and for my failure in that regard, i got my 15 seconds of fame.

---
class: center
# 15 seconds of fame
???
- stressful
- time consuming
- many reporters contacted me, looking for a choice quote from me to put in their summary of the 538 article
- beecause everyone loves a scandal, and the narrative had been set
- so they weren't interested in the process, nor the nuanced facts.
- I wasn't prepared for the onslaught.
- I don't have many regrets,

- but i do kind of regret that i
- didn't have something to sell
- i don't mean merchandise, stickers, or anything to hasten my retirement
- i mean my own career and story
   - the local NPR station figured out that I lived in seattle, and asked me to come on one of their radio programmes
   - but at this point, having seen a bit behind the curtain, I had become very distrustful of the media
- wasn't comfortable w/ attention
- hadn't groomed my online persona in quite awhile
- and by the time it happens it's too late
- advice, be ready for the stampede
- have a website, with a coherent presentation, and some way for people to engage on your terms.
- even if it's just "sign up for my newsletter"

- so after that news cycle died down

---
# Aftermath (6 months)

- kept working

- automated pipeline

- visualization

???
- i kept working, for another 6 months
- imported another 20k puzzles from haldiman collection
- improved and automated my janky pipeline
- came up with a workable visualization

---
## github.com/century-arcade/xd

- Python3

- Amazon Web Services

- $10/year

???
- all of my code for this project is open source and on github
- written mostly in Python3, with no dependencies
- I figured out how to host the entire project on AWS for less than $10/year
---
## visualization - xd.saul.pw

.image-100[![visualization](images/xd-vis.png)]

???
- scope of collection
- scope of plagiarism
- show by comparison

- X-axis: years
- Y-axis: publications
- color: duplications
  - yellow: reprints (same author)
  - pink: are generally theme copies only
  - red: grid duplication with different authors
- within each publication-year square are bar graphs, broken out by day of the week
-  this way, quantity can be directly visually compared

---
.image-100[![visualization](images/xd-vis3.png)]
???
# takeaways
- here is a zoomin to the damning portion of the visualization
- you can see that the scope of the plagiarism was egregious but mostly finite
- there are plenty of other potential instances of plagiarism, which I think are quite interesting
- but they are completely overwhelmed by Timothy Parker's malfeasance
- interestingly, he actually wasn't doing it much anymore when the scandal erupted
  - "only" 9 puzzle self-plagiarisms, and 3 theme reworkings ("gutted puzzles") from newsweek

- here, you can see an odd yellow/red line starting in 2012
- which is when Timothy Parker and USAToday started running pure reprints of puzzles on saturdays
  - why are they half red?
  - they're copies of *other* plagiarized puzzles.
  - this is not obvious before breakout by d-o-w

- and you can dive into this visualization too, first for a list of the puzzles by publication-year, and then into a specific duplicate puzzle comparison.
- for instance...
---
class: center
.image-70[![comparison](images/room-service-3.png)]
???

- this is that same puzzle comparsion we saw earlier, with the usa today puzzle (again on the right) from 2013, attributed to liz gorski, and on the left from 2006 attributed to Tim Burr
- note that the individual puzzle comparison looks more polished
- but the basic .xd structure and format is still very evident
- the clue format is identical to the raw .xd file--even with a tilde to separate the answer from the clue

---
class: center
.image-70[![comparison](images/room-service-1.png)]
???
- here is more of the full story behind that odd pair.
- the puzzle that triggered my spidey sense turned out to be one of those legitimate reprints.
- The original puzzle was published by universal in 2000, and was attributed to...Elizabeth C. Gorski.
- The grid is identical, the title is the same (ROOM SERVICE), and the author is correctly attributed in the reprint.
- (although Timothy Parker did also include himself as an author)
- but, there's more
---
class: center
.image-70[![comparison](images/room-service-2.png)]
???
- the puzzle was first republished in 2005, with the upper left corner of the grid changed, and the puzzle author listed as "Lucia Cole"
- then it was republished in 2006 under Tim Burr as we just saw.
---
class: center
.image-70[![comparison](images/room-service-4.png)]
???
- and then in 2009 the puzzle was gutted and the theme reused
- in total,
---
class: center, middle
.image-100[![comparison](images/room-service.png)]

???

xd.saul.pw/specific puzzle

- in total, at least as I've found anyway, this puzzle was reprinted not just once, but 4 separate times
- and you can tell that these weren't accidental reproductions, because in every instance the black squares in the grid are also placed identically.
- and this is just one puzzle, out of hundreds that were similarly hacked up and reattributed.
---
exclude: true
class: center
### One more anomaly

.image-100[![comparison](images/univ2011-11.png)]
???
- okay, so he stole puzzles from himself and falsified attribution many times
- he's just a greedy hack, right?
- but that's not quite all of it...
- here's one more anomaly that I haven't yet figured out

- from USAToday Nov 2011
- all of these puzzles were originally by Marjorie Richter
---
exclude: true
class: center
### One more anomaly
.image-100[![comparison](images/usa2011-11.png)]
???
- and here, Universal uClick, Nov 2011
- 34 puzzles in a row
- originals all by Marjorie Richter
- not an accident
- he singled her out for som reason, but she never would have known
- this is the biggest mystery remaining for me
---
class: center
# Conclusion

1. simple format
2. easy exploration
3. more results?

# xd.saul.pw/data

???

- The simple .xd format was indeed instrumental in discovering this scandal.
- if i had thought to go looking for it, i suppose I would have found it with other formats
- but i wasn't going to look for it
- but this format and structure made it so trivial to do these explorations and comparisons, that it literally just 'fell out' of the data

- These days, the xd code is still running nightly and collecting and comparing crosswords,
- but I have don't have a whole lot of time to do much more with it
- so, if anyone is interested in playing with an epic dataset, peeled and cleaned like so many baby carrots
- this is the "largest collection of crossword data on the planet".
- especially you should talk with me if you want to play at being a crossword librarian (there are still hundreds of puzzles to be imported)

- Finally, I'd like to encourage you to explore your datasets in a less directed fashion
- When you don't know what you're looking for, try a format-first approach
- make the data exploration easy, frictionless
- There's some low hanging fruit out there, just waiting to fall out.
- and if you find some, please let me know.


---
exclude: true
class: middle, center
# Where are they now?

- Timothy Parker
- xd
- me

???

- In conclusion, where are we now?
- Mr. Parker is still editing crosswords [at Universal]
  - which is still syndicated in many newspapers, including the Seattle Times
- xd is still running autonomously, but with minimal input and no audience
- there are several thousand more crosswords in the haldiman collection to import
- but I have a job, and other projects like the awesome data exploration tool VisiData

---
exclude: true
class: center
# Where are we now?

- Timothy Parker
- xd
- Saul Pwanson
- Timothy Parker still editing
- xd still running
- lots more could be done
- I have new awesome projects

.image-80[![visidata](images/vdlogo.png)]

???

- but I have a job, and other projects like the awesome data exploration tool VisiData

---
exclude: true
class: center

# Anyone interested?

  - crossword nut
  - data nerd
  - librarian
  - sysadmin

???

---
class: center
# Thanks for listening

<br/>
## Saul Pwanson
<br/>
## email: xd@saul.pw
## twitter: @saulfp
## www: visidata.org

???
- I'd like to thank Anja for her support in putting together this talk.
- and I'd like to thank you for listening!
- any questions?
    </textarea>
    <script src="remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>
